%
% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf]{acmart}
\usepackage{hyperref}
%\documentclass{acmart}

%
% defining the \BibTeX command - from Oren Patashnik's original BibTeX documentation.
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08emT\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
% Rights management information. 
% This information is sent to you when you complete the rights form.
% These commands have SAMPLE values in them; it is your responsibility as an author to replace
% the commands and values with those provided to you when you complete the rights form.
%
% These commands are for a PROCEEDINGS abstract or paper.
%\copyrightyear{2018}
%\acmYear{2018}
%\setcopyright{acmlicensed}
%\acmConference[Woodstock '18]{Woodstock '18: ACM Symposium on Neural Gaze Detection}{June 03--05, 2018}{Woodstock, NY}
% \acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection, June 03--05, 2018, Woodstock, NY}
% \acmPrice{15.00}
% \acmDOI{10.1145/1122445.1122456}
% \acmISBN{978-1-4503-9999-9/18/06}

%
% These commands are for a JOURNAL article.
%\setcopyright{acmcopyright}
%\acmJournal{TOG}
%\acmYear{2018}\acmVolume{37}\acmNumber{4}\acmArticle{111}\acmMonth{8}
%\acmDOI{10.1145/1122445.1122456}

%
% Submission ID. 
% Use this when submitting an article to a sponsored event. You'll receive a unique submission ID from the organizers
% of the event, and this ID should be used as the parameter to this command.
%\acmSubmissionID{123-A56-BU3}

%
% The majority of ACM publications use numbered citations and references. If you are preparing content for an event
% sponsored by ACM SIGGRAPH, you must use the "author year" style of citations and references. Uncommenting
% the next command will enable that style.
%\citestyle{acmauthoryear}

%
% end of the preamble, start of the body of the document source.
\begin{document}

%\bibliography{/Users/ClayElmore/Desktop/mendeley/DMD_Literature.bib}

%
% The "title" command has an optional parameter, allowing the author to define a "short title" to be used in page headers.
\title{Stochastic Energy Market Price Forecasting with Recurrent Neural Networks}

%
% The "author" command and its associated commands are used to define the authors and their affiliations.
% Of note is the shared affiliation of the first two authors, and the "authornote" and "authornotemark" commands
% used to denote shared contribution to the research.

\author{Elmore, Clay}
%\authornote{Both authors contributed equally to this research.}
\email{celmore1@nd.edu}
\affiliation{%
  \institution{University of Notre Dame}
}

\author{Kopp, Grace}
\email{gkopp@nd.edu}
\affiliation{%
  \institution{University of Notre Dame}
}
%
% By default, the full list of authors will be used in the page headers. Often, this list is too long, and will overlap
% other information printed in the page headers. This command allows the author to define a more concise list
% of authors' names for this purpose.
\renewcommand{\shortauthors}{Elmore and Kopp, et al.}

% ============================================================================================================================= %
%														Abstract																       %
% ============================================================================================================================= %

\begin{abstract}
Energy market forecasting is a necessary for the functional operation of electricity markets across the globe. Because of large price swings in energy prices, sometimes as much as 4 times, there is a large economic opportunity for accurate forecasting to incur profit for energy users. However, these prices are notoriously hard to predict accurately because of the large stochastic nature inherent to the problem. In this paper we use Recurrent Neural Networks to forecast Day Ahead Market (DAM) prices in the California Independent System Operator (CAISO) in 2015. The study consists of forecasting 24 hour increments for a week in January for 50 different energy providers in the CAISO. Furthermore, a full year of prices is forecasted for a single Californian energy resource for all of 2015. We show that a full year's worth of forecasting in California has an average error of around 10\%. This is on par with current standards in traditional forecasting methods. It is also shown that Recurrent Neural Networks are more resistant to changes in market dynamics involving seasonal changes than traditional methods such as ARIMA or GARCH. 
\end{abstract}

%
% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
% Please copy and paste the code instead of the example below.
%
% \begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>10010520.10010553.10010562</concept_id>
%   <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10010520.10010575.10010755</concept_id>
%   <concept_desc>Computer systems organization~Redundancy</concept_desc>
%   <concept_significance>300</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10010520.10010553.10010554</concept_id>
%   <concept_desc>Computer systems organization~Robotics</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10003033.10003083.10003095</concept_id>
%   <concept_desc>Networks~Network reliability</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
% </ccs2012>
% \end{CCSXML}

% \ccsdesc[500]{Computer systems organization~Embedded systems}
% \ccsdesc[300]{Computer systems organization~Redundancy}
% \ccsdesc{Computer systems organization~Robotics}
% \ccsdesc[100]{Networks~Network reliability}

%
% Keywords. The author(s) should pick words that accurately describe the work being
% presented. Separate the keywords with commas.
\keywords{machine learning, stochastic forecasting, recurrent neural networks, energy markets}

%
% A "teaser" image appears between the author and affiliation information and the body 
% of the document, and typically spans the page. 
% \begin{teaserfigure}
%   \includegraphics[width=\textwidth]{sampleteaser}
%   \caption{Seattle Mariners at Spring Training, 2010.}
%   \Description{Enjoying the baseball game from the third-base seats. Ichiro Suzuki preparing to bat.}
%   \label{fig:teaser}
% \end{teaserfigure}

%
% This command processes the author and affiliation and title information and builds
% the first part of the formatted document.
\maketitle

% ============================================================================================================================= %
%														Intro  																       %
% ============================================================================================================================= %

\section{Introduction}
\label{sec:intro}

Energy markets are present all around the globe. Prices in these markets are extremely volatile due to a variety of different factors including but limited to market demand, erratic weather, natural resource availability, and so much more. Because of the large swings in these prices, participating in these energy markets presents an economic opportunity to both energy buyers and sellers alike. For an energy provider, knowing when the price of energy will be high is critical to knowing when to use valuable resources to produce energy. For an energy user, knowing when to buy energy on the market at a low price can be the difference between an industrial user being profitable or going under. With these considerations in mind, it is clear that energy price forecasting is a worthy venture for academics to study because of its direct applicability to the commercial world.\\

In this paper, we will explore a specific energy market: the California Independent System Operator (CAISO). The CAISO is an enormous, complex energy market system in which energy buyers and sellers schedule a multitude of energy related transactions. The CAISO had some 40 billion dollars in sales, and more than 260,000 gigawatts sold in 2015\cite{CAenergy2}. This complex system makes for a data-rich problem worthy for study by academics and industry professionals alike. A particularly interesting problem in the CAISO is the forecasting of Day-Ahead Market (DAM) prices which are notoriously stochastic. DAM prices are used to forecast energy prices a day in advance which energy buyers and sellers then use to schedule when they will buy and sell energy on the CAISO market. It has been shown that accurate forecasting is absolutely critical to profiting off DAM market prices\cite{Dowling2017}.\\

Although prices in the CAISO DAM are quite volatile, they have very clear periodic tendencies. Figure \ref{fig:ex_prices} shows an example week of energy prices for an energy resource in the CAISO DAM for the first week of 2015. Note how the price is clearly periodic, but also has stochastic tendencies as well. Furthermore, Figure \ref{fig:ex_prices} shows the economic opportunity available to sell at high prices and buy at low prices. Some price swings are almost double the price. An accurate forecast would allow for large amounts of profit to be extracted from these systems.\\

\begin{figure}[h]
\includegraphics[width=0.45\textwidth]{fig_1.png}
\caption{An example of time series behavior observed in the CAISO from January 1st, 2015 to January 7th, 2015.}
\label{fig:ex_prices}
\end{figure}

Many standard time series forecasting methods have been used to predict DAM prices in the CAISO and other energy markets across the globe. For example, standard autoregressive integrated moving average (ARIMA) forecasting methods have been used to differing degrees of success in the CAISO market and the Spanish DAM. Conejo et al. have used ARIMA models to predict prices in the Spanish market with a 10\% error for the 2002 market \cite{Conejo2005a}. Furthermore, ARIMA has been shown to generate forecasts in the 2000 CAISO DAM with an error of around 13\% \cite{Garcia2005}. Another standard method for time series forecasting that has been used in the  Generalized autoregressive conditional heteroskedasticity (GARCH) method. Similar to ARIMA models, an error rate of around 10\% for the Spanish DAM has been reported when using GARCH \cite{Garcia2005}. More advanced hybrid methods have also been used for DAM forecasting. These methods include the usage of wavelet decompositions in order remove noise from data as well as the incorporation of ARIMA models in conjunction with GARCH methods \cite{Conejo2005,Tan2010,Amjady2008,Wang2012}. These various hybrid methods have error rates reported that range from as low as 1\% to as high as 25\%. 

Recent advances in Recurrent Neural Networks (RNN) in the past 5 to 10 years have motivated this project to investigate their potential ability to predict CAISO DAM prices. The remainder of the paper will be organized in the following manner.

\begin{itemize}
	\item Section \ref{sec:approach}: A problem statement along with the design of the RNN, an explanation of the dataset, and software implementation details.
	\item Section \ref{sec:results}: Results of the forecasting performance of our RNN forecaster is presented.
	\item Section \ref{sec:discussion}: A discussion of how RNN forecasting compares to existing methods and other insights from this project.
	\item Section \ref{sec:conclusions}: Major findings from the paper are summarized.
\end{itemize}

% ============================================================================================================================= %
%														Approach																       %
% ============================================================================================================================= %

\section{Modeling Approach}
\label{sec:approach}

\subsection{Problem Statement}
We set out to use a recurrent neural network to forecast Day Ahead Market (DAM) prices of the California Independent System Operator (CAISO)  in 2015. Specifically, we wanted to forecast 7 24 hour increments for a week in January for 50 different energy providers in the CAISO. 

We also set out to get in depth information on one energy provider so we forecasted a full year (2015) of prices for one energy provider.

\subsection{Neural Network Methodology}
We used a recurrent neural network (RNN) for our time series prediction. We chose to use this architecture because RNNs are made to deal with sequential information. In other neural network architectures, it is assumed that all inputs are independent which would not be useful for a time series prediction where the order of the inputs is extremely important to accurately predict outputs. RNNs accomplish this by keeping a “memory” of inputs they have seen at previous timesteps to make decisions about future timesteps. 

\begin{figure}[h]
\includegraphics[width=0.45\textwidth]{tex_writing/rnn.png}
\caption{An unrolled recurrent neural network cell}
\label{fig:rnn}
\end{figure}
\textbf{https://medium.com/themlblog/time-series-analysis-using-recurrent-neural-networks-in-tensorflow-2a0478b00be7}

The figure above depicts an unrolled RNN. For a sequence with t timesteps, we will unroll our network into t corresponding layers. The blue nodes labelled x1,  x2, etc. are our inputs at time step one, two, and so on. In the case of this paper, these would be energy prices at hour 1, hour 2, etc. The green nodes labelled A are our hidden states at each timestep. This is how the network is able to have a memory. It is calculated with the previous hidden step and the current input. Because it takes this previous hidden step into account, it captures information about timesteps that have already been processed. Finally, the purple nodes labelled with h’s are the outputs at each timestep that are calculated from the memory in their associated hidden node. For us, these outputs are the energy prices we are predicting for future timesteps. 

Unfortunately, basic RNNs are not perfect for this task because of the vanishing gradient problem. RNNs are trained with backpropagation and gradient descent learning methods. When dealing with a huge number of timesteps, as is the case in our dataset, calculated gradients can become so small that the neural network is unable to continue to train. 

Our solution to this problem was using a Long-short Term Memory network (LSTM). These are a type of neural network that have input gates, output gates, and forget gates that give the network the ability to keep some information while forgetting other information. This cuts down the amount of data used and solves the vanishing gradient problem. 

\textbf{https://medium.com/themlblog/time-series-analysis-using-recurrent-neural-networks-in-tensorflow-2a0478b00be7}

We wanted to be able to forecast a days worth of energy prices in advance or 24 output timesteps. To accomplish this, we created a Multi-Step LSTM where our output was a vector of 24 prices corresponding to the 24 timesteps in the future we predicted. Our training data was the 168 timesteps (one weeks worth) of data that came directly before the 24 hour testing period.

\textbf{https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/}

In order to get an accurate view of our network and match other current evaluation models for energy price forecasting, for each of the fifty nodes we analyzed, we performed a rolling horizon analysis to predict seven days worth of data. In other words, first we used $t_{0}$ through $t_{167}$ to predict $t_{168}$ through $t_{191}$ , then we used $t_{24}$ through $t_{191}$ to predict $t_{192}$ through $t_{216}$ , and so on five more times until we had seven days of predictions or 168 hours.  

To calculate error, we performed a standard average percent error calculation on our predicted prices vs the actual price. We chose percent error in order to be able to easily compare our results to other energy forecasting results on the same data from different prediction methods.

$$ error = \frac{1}{7}\sum_{i=0}^{6}\frac{1}{24}\sum_{j=0}^{23}\frac{|p_{i,j}-a_{i,j}|}{a_{i,j}}$$

In the above equation $p_{i,j}$ is the predicted energy price on day i, hour j and $a_{i,j}$ is the actual energy price on day i, hour j.

As a supplemental inquiry, we also investigated forecasting a full year of energy prices for one energy provider. This was done almost identically, except for this study we used 336 input timesteps as training to predict 24 hour timestep outputs. We performed this calculation 356 times to see how our RNN performs on more long term data. Error was calculated using the same method above except for 365 days instead of 7:

$$ error = \frac{1}{365}\sum_{i=0}^{364}\frac{1}{24}\sum_{j=0}^{23}\frac{|p_{i,j}-a_{i,j}|}{a_{i,j}}$$


\subsection{Data Sources}
The dataset for this project was kindly provided by the Dowling Lab for Uncertainty Quantification and Mathematical Optimization at the University of Notre Dame in the Department of Chemical and Biomolecular Engineering. The dataset is comprised of over 6500 energy vendors, called nodes, participating in the CAISO. There is a full year's worth of data for each node in 2015, and price measurements are recorded at 1 hour intervals. Latitude and longitude coordinates are known for around 2000 of these nodes for visualization purposes. Because of the limited timeline of this project, only 50 of these nodes will be used, and only a single week of data in January 2015 will be used for testing purposes.  This is a reasonable thing to do as many papers report error values for single weeks in Janurary \cite{Conejo2005a,Garcia2005,Tan2010}. However, a single node will be used to predict prices 24 hours into the future for a full year in order to give a more accurate representation of error quantification across a larger time span. Furthermore, these papers only report results for single nodes in the DAM. Because our results include 50 nodes, it can be concluded that the results obtained for this dataset are statistically significant. 

\subsection{Software Implementation}
This study was implemented using Keras with a TensorFlow backend. Specifically, we used the sequential library in the Keras packaged to define and train our LSTM model. We chose to use Keras because it is allowed us to access the deep learning resources of TensorFlow in an easy to use API. 

Because we were dealing with a huge amount of data, our study had a very high computation time. To make this more manageable, we submitted our code as jobs to the University of Notre Dame Center for Research Computing GPUs. This allowed faster and more convenient processing than if we were to run our model locally. 

Our entire code suite  is available at:

https://github.com/celmore25/neural_net_predictions.

This includes our class implementation of the model, our data, our evaluation tool, and every other piece of code we wrote in pursuit of completing this study. 

This research was supported in part by the Notre Dame Center for Research Computing through the use of available GPU systems. 



% ============================================================================================================================= %
%														Results																       %
% ============================================================================================================================= %
\section{Results}

Now that we have shown how we are going to forecast market prices with a RNN, we will now enter the results section where we analyze the effectiveness of RNNs. 

\label{sec:results}

%Figures and Tables we will need:
%\begin{itemize}
%	\item Figure: Example of what a price forecast looks like (good and bad).
%	\item Figure: Histogram of error values for all nodes.
%	\item Figure: Histogram of what adding more training data does for testing.
%	\item Figure: Histogram of error values for the single node across the whole year.
%	\item Table: Aggregated statistics of all nodes with low and high amounts of training.
%	\item Table: Aggregated statistics of single node across the year.
%	\item Table: Aggregated statistics on CPU time.
%\end{itemize}

It is important to notice that variations in market prices can significantly alter the ability of RNNs to accurately predict DAM prices. Figure \ref{fig:ex_forecast} was constructed by training a RNN with 336 hours of training data, or two weeks. This 336 hour training set was then split into 265 training instances. These instances consisted of one 24 hour input, and the corresponding 24 hour output that would be the next day's market data. Two different forecasts are shown in Figure \ref{fig:ex_forecast} to illustrate how different inputs to the RNN can drastically alter its ability to forecast market prices. In the first plot (top), there is well behaving periodic wave input to the RNN. The output is a forecast that is extremely successful with a small error of only 4.4\%. However, the second plot (bottom) shows that when there is an input that does not as 

\begin{figure}[h]
\includegraphics[width=0.45\textwidth]{fig_3.png}
\caption{Example price forecasting using our RNN.}
\label{fig:ex_forecast}
\end{figure}

\begin{figure}[h]
\includegraphics[width=0.45\textwidth]{fig_5.png}
\caption{Histogram of all nodes.}
\label{fig:hist_small}
\end{figure}

% Still running on CRC

%\begin{figure}[h]
%\includegraphics[width=0.45\textwidth]{fig_6.png}
%\caption{Histogram of all nodes now with larger amounts of training data.}
%\label{fig:hist_large}
%\end{figure}

\begin{table}[h]
\begin{tabular}{lll}
\hline
Training Data Used & 1 week & 2 weeks \\
\hline
Median             & 14.49  & N/A     \\
Mean               & 14.34  & N/A     \\
Standard Deviation & 3.13   & N/A    \\
\hline
\end{tabular}
\caption{Aggregated statistical performance for a single week in January when 1 week of training data was used vs. 2 weeks of training data (2 week data is running currently).}
\label{tab:all_nodes}
\end{table}

\begin{figure}[h]
\includegraphics[width=0.45\textwidth]{fig_7.png}
\caption{Histogram of a single node run through the whole year.}
\label{fig:hist_single}
\end{figure}

\begin{figure}[h]
\includegraphics[width=0.45\textwidth]{fig_8.png}
\caption{Time series plot of a single node run through the whole year.}
\label{fig:time_single}
\end{figure}

\begin{table}[h]
\begin{tabular}{llllll}
\hline
Quarter & All   & 1    & 2    & 3     & 4     \\
\hline
Median  & 8.89  & 8.39 & 9.34 & 9.29  & 8.80  \\
Mean    & 10.14 & 9.60 & 9.67 & 10.53 & 10.74 \\
Std.    & 4.59  & 4.78 & 3.03 & 4.67  & 5.41 \\
\hline
\end{tabular}
\caption{Aggregated statistical performance for a single node in 2015.}
\label{tab:single}
\end{table}


% ============================================================================================================================= %
%														Discussion															       %
% ============================================================================================================================= %
\section{Discussion}
\label{sec:discussion}

Figures and Tables we will need:
\begin{itemize}
	\item Figure: Graphical comparison of how backcasting does not do what the RNN can do.
	\item Figure/Table: Comparison to techniques that have been mentioned earlier in the paper and backcasting.
\end{itemize}

% ============================================================================================================================= %
%														Conclusions															       %
% ============================================================================================================================= %
\section{Conclusions and Future Work}
\label{sec:conclusions}

% ============================================================================================================================= %
%														References															       %
% ============================================================================================================================= %

%\section{Related Work}
%\begin{itemize}
%    \item Here provide the relevant references for your work. 
%\end{itemize}
%	
%\emph{Use the standard Communications of the ACM format for references --- that is, a numbered list at the end of the article, ordered alphabetically by first author, and referenced by numbers in brackets~. See the examples of citations at the end of this document. Within this template file, use the style named references for the text of your citation.}
%
%\emph{References should be published materials accessible to the public. Internal technical reports may be cited only if they are easily accessible (i.e. you can give the address to obtain the report within your citation) and may be obtained by any reader. Proprietary information may not be cited. Private communications should be acknowledged, not referenced  (e.g., ``[Robertson, personal communication]").}


\bibliographystyle{ACM-Reference-Format}
%\bibliography{acmart.bib}
\bibliography{/Users/ClayElmore/Desktop/mendeley/DMD_Literature.bib}
\end{document}
